#!/usr/bin/env python3
"""
ParallelAI Research Edition - Academic-focused multi-LLM analyzer
"""
import os
import sys
import json
import requests
from pathlib import Path
from datetime import datetime
from typing import Dict, List

def enhance_for_research(original_prompt: str) -> str:
    """Format queries for academic rigor and reproducibility."""
    return f"""As a security researcher with ORCID 0009-0005-3020-9694, analyze: '{original_prompt}'

Provide a structured analysis suitable for academic publication with:

1. **THEORETICAL CONTEXT**: Place within existing security frameworks and cite relevant literature.
2. **METHODOLOGY**: Suggest reproducible analysis methods with specific tools/commands.
3. **FINDINGS**: Present clear, evidence-based conclusions in bullet points.
4. **ETHICAL & LEGAL CONSIDERATIONS**: Note relevant compliance (GDPR, CFAA, etc.).
5. **LIMITATIONS**: State model limitations, assumptions, and knowledge cutoffs.
6. **CITATIONS**: Suggest 2-3 key papers (Author, Year, Title, DOI if possible).
7. **FUTURE RESEARCH**: Propose specific, testable hypotheses for follow-up.
8. **REPRODUCIBILITY**: Provide exact commands to replicate this analysis.

Format response using markdown with clear section headers."""

class ResearchParallelAI:
    def __init__(self):
        self.load_env()
        self.setup_providers()
    
    def load_env(self):
        """Load environment variables for research context."""
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file) as f:
                for line in f:
                    line = line.strip()
                    if line and '=' in line and not line.startswith('#'):
                        key, val = line.split('=', 1)
                        os.environ[key.strip()] = val.strip().strip('"').strip("'")
        
        # Add research context to environment
        os.environ['RESEARCHER_ORCID'] = '0009-0005-3020-9694'
        os.environ['RESEARCH_TOOL'] = 'ParallelAI Research Edition'
    
    def setup_providers(self):
        """Configure AI providers with research-optimized parameters."""
        self.providers = [
            {
                'name': 'groq',
                'url': 'https://api.groq.com/openai/v1/chat/completions',
                'key': os.getenv('GROQ_API_KEY'),
                'model': 'llama-3.3-70b-versatile',
                'temperature': 0.3,  # Lower for more deterministic/research output
                'headers': lambda key: {
                    'Authorization': f'Bearer {key}',
                    'Content-Type': 'application/json'
                }
            },
            {
                'name': 'together',
                'url': 'https://api.together.xyz/v1/chat/completions',
                'key': os.getenv('TOGETHER_API_KEY'),
                'model': 'mistralai/Mixtral-8x7B-Instruct-v0.1',
                'temperature': 0.3,
                'headers': lambda key: {
                    'Authorization': f'Bearer {key}',
                    'Content-Type': 'application/json'
                }
            }
        ]
    
    def query_research(self, prompt: str, max_tokens: int = 500) -> Dict:
        """Execute research-optimized query across all providers."""
        research_prompt = enhance_for_research(prompt)
        
        print(f"ğŸ§ª RESEARCH MODE: {prompt[:80]}...")
        print(f"ğŸ“š Enhanced for academic rigor (ORCID: 0009-0005-3020-9694)")
        print("=" * 60)
        
        results = {}
        for provider in self.providers:
            if not provider['key'] or len(provider['key']) < 20:
                print(f"âš ï¸  Skipping {provider['name']} - API key missing")
                continue
            
            print(f"ğŸ”¬ Querying {provider['name']} ({provider['model']})...")
            
            try:
                headers = provider['headers'](provider['key'])
                payload = {
                    'model': provider['model'],
                    'messages': [
                        {
                            'role': 'system',
                            'content': 'You are a cybersecurity research assistant helping with reproducible academic analysis.'
                        },
                        {'role': 'user', 'content': research_prompt}
                    ],
                    'max_tokens': max_tokens,
                    'temperature': provider['temperature'],
                    'top_p': 0.9
                }
                
                response = requests.post(
                    provider['url'],
                    json=payload,
                    headers=headers,
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data.get('choices', [{}])[0].get('message', {}).get('content', '')
                    
                    results[provider['name']] = {
                        'success': True,
                        'model': provider['model'],
                        'response': content,
                        'tokens_used': data.get('usage', {}).get('total_tokens', 0)
                    }
                    
                    # Print first 200 chars of response
                    preview = content[:200].replace('\n', ' ')
                    print(f"   âœ… {preview}...")
                else:
                    error_msg = f"HTTP {response.status_code}"
                    results[provider['name']] = {
                        'success': False,
                        'error': error_msg
                    }
                    print(f"   âŒ {error_msg}")
                    
            except Exception as e:
                error_msg = str(e)[:100]
                results[provider['name']] = {
                    'success': False,
                    'error': f'Connection: {error_msg}'
                }
                print(f"   âŒ {error_msg}")
        
        return results

def main():
    if len(sys.argv) < 2 or sys.argv[1] in ['--help', '-h']:
        print("""
ParallelAI Research Edition
==========================
Usage:
  ./parallelai-research "your research question"
  
Example:
  ./parallelai-research "Comparative analysis of Mirai vs Zeus botnet C2 architecture"
  
Features:
  â€¢ Academic-structured responses
  â€¢ Reproducibility-focused
  â€¢ ORCID-integrated (0009-0005-3020-9694)
  â€¢ Multi-LLM comparison for research rigor
        """)
        return
    
    prompt = ' '.join(sys.argv[1:])
    
    researcher = ResearchParallelAI()
    results = researcher.query_research(prompt)
    
    # Print formatted results
    print("\n" + "=" * 60)
    print("ğŸ“Š RESEARCH RESULTS SUMMARY")
    print("=" * 60)
    
    for provider, result in results.items():
        if result.get('success'):
            print(f"\nğŸ”¬ {provider.upper()} ({result.get('model', 'N/A')}):")
            print("-" * 40)
            print(result['response'][:500] + ("..." if len(result['response']) > 500 else ""))
            if 'tokens_used' in result:
                print(f"\nğŸ“ˆ Tokens used: {result['tokens_used']}")
        else:
            print(f"\nâŒ {provider.upper()}: {result.get('error', 'Failed')}")
    
    print("\n" + "=" * 60)
    print("ğŸ’¡ For complete analysis, use: ./log_experiment.sh <id> \"<query>\"")
    print("ğŸ“š ORCID: 0009-0005-3020-9694 | GitHub: jasonclarkagain/parallelai")
    print("=" * 60)

if __name__ == "__main__":
    main()
